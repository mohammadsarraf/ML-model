{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5430762",
   "metadata": {},
   "source": [
    "## NBA Model TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63016ff0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshap\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6db4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the seasons and models used\n",
    "seasons = ['2021-22', '2023-24', '2022-23','2020-21','2019-20','2018-19','2017-18','2016-17','2015-16','2014-15','2013-14',\n",
    "          '2012-13','2011-12','2010-11','2009-10','2008-09','2007-08','2006-07','2005-06', '2004-05', '2003-04','2002-03','2001-02'] \n",
    "          \n",
    "modelos = ['SVM','Elastic Net','Random Forest','AdaBoost','Gradient Boosting','LGBM']\n",
    "\n",
    "# seasons = ['2021_2022', '2001_2002', '2002_2003', '2003_2004', '2004_2005', '2005_2006', \n",
    "#           '2006_2007', '2007_2008', '2008_2009',  '2009_2010', '2010_2011', '2011_2012', '2012_2013', \n",
    "#           '2013_2014', '2014_2015', '2015_2016', '2016_2017', '2017_2018', '2018_2019', '2019_2020',   \n",
    "#           '2020_2021']\n",
    "# modelos = ['SVM','Elastic Net','Random Forest','AdaBoost','Gradient Boosting','LGBM']\n",
    "\n",
    "# Path to local folder\n",
    "path_data = r'./data/'\n",
    "\n",
    "# sep = r'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db8678c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _perGame = pd.DataFrame()\n",
    "# _perGame = pd.read_csv('./data/2023-24 Totals.csv')\n",
    "# _perGame['Player'] = _perGame['Player'] + '\\\\' + _perGame['Player-additional']\n",
    "# _perGame = _perGame.drop(columns=['Player-additional'])\n",
    "# _perGame.to_csv('./2023-24 Totals.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a074882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(seasons):\n",
    "# Opening the data\n",
    "    perGame = pd.DataFrame()\n",
    "    totals = pd.DataFrame()\n",
    "    advanced = pd.DataFrame()\n",
    "    standings = pd.DataFrame()\n",
    "    \n",
    "    for season in seasons:\n",
    "\n",
    "        _advanced = pd.read_csv(path_data  + season + \" Advanced.csv\")\n",
    "        \n",
    "        _perGame = pd.read_csv(path_data + season + ' perGame.csv')\n",
    "\n",
    "        _standings = pd.read_csv(path_data  + season + ' Standings.csv')\n",
    "        \n",
    "        _totals = pd.read_csv(path_data  + season + ' Totals.csv')\n",
    "        \n",
    "\n",
    "        _perGame['Season'] = season\n",
    "        _totals['Season'] = season\n",
    "        _advanced['Season'] = season\n",
    "        _standings['Season'] = season\n",
    "        \n",
    "        perGame = pd.concat([perGame,_perGame], ignore_index=True)\n",
    "        totals = pd.concat([totals,_totals], ignore_index=True)\n",
    "        advanced = pd.concat([advanced,_advanced], ignore_index=True)\n",
    "        standings = pd.concat([standings,_standings], ignore_index=True)\n",
    "            \n",
    "    return advanced, perGame, standings, totals;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "628e03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for season in seasons:\n",
    "#   _standings = pd.read_csv(path_data + \"nba\" + season + \" Standings.csv\", skiprows=1)\n",
    "#   # _standings.drop(index=_standings.index[0], axis=0, inplace=True)\n",
    "#   df = _standings[['Rk', 'Team', 'Overall']]\n",
    "#   df.rename(columns={'Rk': 'Seed', 'Overall': 'Record'}, inplace=True)\n",
    "#   print(df.columns)\n",
    "#   df.to_csv(path_data + \"nba\" + season + \" Standings.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72b5b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_data(advanced, perGame, standings, totals, seasons):\n",
    "    \n",
    "    # Removing duplicate/empty columns\n",
    "    perGame = perGame.drop(['Rk','Pos',], axis=1)\n",
    "    totals = totals.drop(['Rk','Pos','Age','G','GS',], axis=1)\n",
    "    advanced = advanced.drop(['Rk','Pos','Age','G','MP','Unnamed: 24','Unnamed: 19', ], axis=1)\n",
    "    \n",
    "    cols = ['Player','Season','Pos','Age','Tm','G','GS']\n",
    "    \n",
    "    # Identifying the variables\n",
    "    for column in perGame.columns:\n",
    "        if column not in cols:\n",
    "            newCol = column+'_perGame'\n",
    "            perGame = perGame.rename(columns={column:newCol})\n",
    "    for column in totals.columns:\n",
    "        if column not in cols:\n",
    "            newCol = column+'_totals'\n",
    "            totals = totals.rename(columns={column:newCol})\n",
    "    for column in advanced.columns:\n",
    "        if column not in cols:\n",
    "            newCol = column+'_advanced'\n",
    "            advanced = advanced.rename(columns={column:newCol})\n",
    "            \n",
    "    # Merging the bases\n",
    "    data = perGame.merge(advanced, on=['Player','Season','Tm'], how='left', validate='1:1')\n",
    "    data = data.merge(totals, on=['Player','Season','Tm'], how='left', validate='1:1')\n",
    "    \n",
    "    dict_teams = {'Utah Jazz':'UTA','Phoenix Suns':'PHO',\n",
    "                'Philadelphia 76ers':'PHI','Brooklyn Nets':'BRK',\n",
    "                'Denver Nuggets':'DEN','Los Angeles Clippers':'LAC',\n",
    "                'Milwaukee Bucks':'MIL','Dallas Mavericks':'DAL',\n",
    "                'Los Angeles Lakers':'LAL','Portland Trail Blazers':'POR',\n",
    "                'Atlanta Hawks':'ATL','New York Knicks':'NYK',\n",
    "                'Miami Heat':'MIA','Golden State Warriors':'GSW',\n",
    "                'Memphis Grizzlies':'MEM','Boston Celtics':'BOS',\n",
    "                'Washington Wizards':'WAS','Indiana Pacers':'IND',\n",
    "                'Charlotte Hornets':'CHO','Charlotte Bobcats':'CHA',\n",
    "                'San Antonio Spurs':'SAS','Chicago Bulls':'CHI',\n",
    "                'New Orleans Pelicans':'NOP','Sacramento Kings':'SAC',\n",
    "                'Toronto Raptors':'TOR','Minnesota Timberwolves':'MIN',\n",
    "                'Cleveland Cavaliers':'CLE','Oklahoma City Thunder':'OKC',\n",
    "                'Orlando Magic':'ORL','Detroit Pistons':'DET',\n",
    "                'Houston Rockets':'HOU','New Jersey Nets':'NJN',\n",
    "                'New Orleans Hornets':'NOH','Seattle SuperSonics':'SEA'}\n",
    "    \n",
    "    teams = pd.DataFrame.from_dict(dict_teams, orient='index').reset_index()\n",
    "    teams = teams.rename(columns={'index':'Team',0:'Tm'})\n",
    "    standings = standings.merge(teams, on='Team', how='left', validate='m:1')\n",
    "    wins = (standings['Record'].str.split('-',expand=True)[0]).astype(int)\n",
    "    games = ((standings['Record'].str.split('-',expand=True)[0]).astype(int)+(standings['Record'].str.split('-',expand=True)[1]).astype(int))\n",
    "    standings['WIN%'] = wins/games\n",
    "    \n",
    "    data = data.merge(standings, on=['Tm','Season'], how='left', validate='m:1')\n",
    "    \n",
    "    data['Player'] = data['Player'].str.replace('*','')\n",
    "    \n",
    "    mvps = pd.read_csv(path_data + \"MVPs.csv\")\n",
    "    data = data.merge(mvps, on=['Player','Season'], how='left', validate='m:1').fillna(0)  \n",
    "\n",
    "    data['Player'] = data['Player'].str.split('\\\\', expand=True)[0]\n",
    "    \n",
    "    # Removing duplicate lines from traded players\n",
    "    dataf = pd.DataFrame()\n",
    "    for season in seasons:\n",
    "        data_season = data[data['Season']==season]\n",
    "        data_season = data_season.drop_duplicates(subset=['Player'], keep='first')\n",
    "\n",
    "        dataf = pd.concat([dataf,data_season], ignore_index=True)\n",
    "    \n",
    "    # Filtering the data\n",
    "    # dataf = dataf[((dataf['G']>48)&(dataf['PTS_perGame']>13.5)&(dataf['MP_perGame']>30)\n",
    "    #             &(dataf['Seed']<=16)&(dataf['AST_perGame']>1)&(dataf['TRB_perGame']>3)\n",
    "    #             &(dataf['Tm']!='TOT')&(dataf['FG%_perGame']>0.37)&(dataf['FGA_perGame']>10)\n",
    "    #             &(dataf['PER_advanced']>18))].reset_index(drop=True)\n",
    "    dataf = dataf[((dataf['PTS_perGame']>13.5)&(dataf['MP_perGame']>30)\n",
    "            &(dataf['Seed']<=16)&(dataf['AST_perGame']>1)&(dataf['TRB_perGame']>3)\n",
    "            &(dataf['Tm']!='TOT')&(dataf['FG%_perGame']>0.37)&(dataf['FGA_perGame']>10)\n",
    "            &(dataf['PER_advanced']>18))].reset_index(drop=True)\n",
    "    # Base for the criteria:\n",
    "    # Karl Malone was MVP in 98-99 with 49 games\n",
    "    # Wes Unseld was MVP at 68-69 with 13.8 PPG and with 10.9 FGA\n",
    "    # Steve Nash was MVP at 04-05 with 3.3 REB\n",
    "    # Moses Malone was MVP at 82-83 with 1.3 AST\n",
    "    # Bob Cousy was MVP at 56-57 with 37.8% FG\n",
    "    # Giannis Antetokounmpo was MVP in 19-20 with 30.4 min\n",
    "    # Kareem Abdul-Jabbar was the only MVP not to make the playoffs in 1976 (40-42)\n",
    "    # Dave Cowens was MVP at 72-73 with a PER of 18.1\n",
    "    # Never has an MVP been traded in the middle of the season that he won the award\n",
    "        \n",
    "    dataf = dataf.drop(['Tm','Team','Record'], axis=1)\n",
    "    \n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d9cfebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced, perGame, standings, totals = get_data(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58f9395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = treat_data(advanced, perGame, standings, totals, seasons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d453a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns # Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec80991",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Season'].value_counts() # Number of players in the data per season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f327b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for metrics\n",
    "def func_metricas(y_test, y_pred, metricas, modelo, season):\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_test, y_pred)),3) # RMSE\n",
    "    r2 = round(r2_score(y_test, y_pred),3) # R²\n",
    "    \n",
    "    dict_met = {'Modelo': [modelo],\n",
    "                'Season': [season],\n",
    "                'RMSE': [rmse],\n",
    "                'R²': [r2]}\n",
    "    \n",
    "    metrica = pd.DataFrame(data=dict_met)\n",
    "    metricas = pd.concat([metricas,metrica])\n",
    "    \n",
    "    return metricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e34b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_modelos(data, seasons, modelos, n_seasons_to_test):\n",
    "    final_results = pd.DataFrame()\n",
    "    metricas = pd.DataFrame()\n",
    "    best_params = []\n",
    "    i = 1\n",
    "\n",
    "    for season in seasons:\n",
    "\n",
    "        # Separating training and testing bases\n",
    "        season_teste = season\n",
    "\n",
    "        data_train = data[data['Season']!=season_teste]\n",
    "        data_test = data[data['Season']==season_teste]\n",
    "\n",
    "        X_train = data_train.drop(['MVP Votes Share','MVP Rank','Player','Season'], axis=1)\n",
    "        y_train = data_train['MVP Votes Share']\n",
    "\n",
    "        X_test = data_test.drop(['MVP Votes Share','MVP Rank','Player','Season'], axis=1)\n",
    "        y_test = data_test['MVP Votes Share']\n",
    "\n",
    "        initial_results = data_test[['Player','Season','MVP Votes Share','MVP Rank']]\n",
    "        results = initial_results.copy()\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        scaled_X_train = scaler.fit_transform(X_train)\n",
    "        scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "        for modelo in modelos:\n",
    "            # Creating instance for each model\n",
    "            if modelo=='SVM':\n",
    "                param_grid = {'C': [0.001,0.01,0.1,0.5,1,2,5,10],\n",
    "                             'kernel': ['linear','rbf','poly'],\n",
    "                             'gamma': ['scale','auto'],\n",
    "                             'degree': [2,3,4],\n",
    "                             'epsilon': [0.1,0.5,1]}\n",
    "                svr_model = SVR()\n",
    "                grid = GridSearchCV(svr_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = SVR(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "\n",
    "            elif modelo=='Elastic Net':\n",
    "                param_grid = {'alpha':[0.01,0.1,1,5,10,50,100],\n",
    "                              'l1_ratio':[0.01,0.1,0.5,0.7,0.95,0.99,1]}\n",
    "                elastic_net_model = ElasticNet()\n",
    "                grid = GridSearchCV(elastic_net_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                grid.best_params_\n",
    "                model = ElasticNet(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            elif modelo=='Random Forest':\n",
    "                param_grid = {'n_estimators': [15,25,50,64,100,150,200],\n",
    "                             'max_features': [2,3,4,5],\n",
    "                             'bootstrap': [True,False],\n",
    "                             'oob_score': [True]}\n",
    "                rfc = RandomForestRegressor()\n",
    "                grid = GridSearchCV(rfc, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = RandomForestRegressor(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            elif modelo=='AdaBoost':\n",
    "                param_grid = {'n_estimators': [5,10,20,30,40,50,100],\n",
    "                             'learning_rate': [0.01,0.05,0.1,0.2,0.5]}\n",
    "                ada_model = AdaBoostRegressor()\n",
    "                grid = GridSearchCV(ada_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = AdaBoostRegressor(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            elif modelo=='Gradient Boosting':\n",
    "                param_grid = {'n_estimators': [10,20,30,40,50],\n",
    "                             'learning_rate': [0.01,0.05,0.1,0.2,0.5],\n",
    "                             'max_depth': [3,4,5]}\n",
    "                gb_model = GradientBoostingRegressor()\n",
    "                grid = GridSearchCV(gb_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = GradientBoostingRegressor(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            elif modelo=='LGBM':\n",
    "                param_grid = {'learning_rate':[0.01,0.1,0.2,0.3],\n",
    "                              'num_leaves':[5,10,20,30],\n",
    "                              'min_data_in_leaf':[10,25,50],\n",
    "                              'max_depth':[2,3,4],\n",
    "                              'feature_fraction':[0.6,0.7,0.8,0.9],\n",
    "                              'min_gain_to_split':[0,0.01,0.1,0.2],\n",
    "                              'verbose':[-1]}\n",
    "                lgbm_model = LGBMRegressor()\n",
    "                grid = GridSearchCV(lgbm_model, param_grid)\n",
    "                grid.fit(scaled_X_train, y_train)\n",
    "                model = LGBMRegressor(**grid.best_params_)\n",
    "                best_params.append(grid.best_params_)\n",
    "                \n",
    "            model.fit(scaled_X_train, y_train)\n",
    "            \n",
    "            pickle.dump(model, open(path_data + modelo + '.dat', 'wb'))\n",
    "\n",
    "            \n",
    "            y_pred = model.predict(scaled_X_test)\n",
    "            metricas = func_metricas(y_test, y_pred, metricas, modelo, season)\n",
    "\n",
    "            apoio = initial_results.copy()\n",
    "            apoio['Predicted MVP Share '+modelo] = pd.Series(y_pred).values\n",
    "\n",
    "            results_sorted = apoio.sort_values(by='Predicted MVP Share '+modelo,\n",
    "                                                ascending=False).reset_index(drop=True)\n",
    "            results_sorted['MVP Rank '+modelo] = results_sorted.index+1\n",
    "\n",
    "            results = results.merge(results_sorted, on=['Player','Season','MVP Votes Share','MVP Rank'])\n",
    "\n",
    "        final_results = pd.concat([final_results,results], ignore_index=True)\n",
    "\n",
    "        if i == n_seasons_to_test:\n",
    "            break\n",
    "\n",
    "        i = i + 1\n",
    "    \n",
    "    np.savetxt(path_data+ 'params.csv', best_params, delimiter =', ', fmt ='% s')\n",
    "    \n",
    "    return final_results, metricas, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bfd3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_metricas(metricas):\n",
    "    # Averages of each of the models\n",
    "    final_metricas = pd.DataFrame()\n",
    "    for modelo in metricas['Modelo'].unique():\n",
    "        metrica = metricas[metricas['Modelo']==modelo]\n",
    "        rmse = round(metrica['RMSE'].mean(),3)\n",
    "        r2 = round(metrica['R²'].mean(),3)\n",
    "\n",
    "        dict_met = {'Modelo': [modelo],\n",
    "                    'RMSE': [rmse],\n",
    "                    'R²': [r2]}\n",
    "\n",
    "        apoio = pd.DataFrame(data=dict_met)\n",
    "        final_metricas = pd.concat([final_metricas,apoio], ignore_index=True)\n",
    "    return final_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e12efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results, metricas, best_params = func_modelos(data, seasons, modelos, 1)\n",
    "final_metricas = media_metricas(metricas)\n",
    "final_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23dda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rank(final_results, n_rank):\n",
    "    rank_final = pd.DataFrame()\n",
    "\n",
    "    for season in final_results['Season'].unique():\n",
    "        temp = final_results[final_results['Season']==season]\n",
    "        rank = pd.DataFrame()\n",
    "        rank_real = temp.sort_values(by='MVP Votes Share', ascending=False)[:n_rank].reset_index(drop=True)\n",
    "        rank['MVP Rank Real'] = rank_real['Player']\n",
    "        rank['MVP Share Real'] = rank_real['MVP Votes Share']\n",
    "        for modelo in modelos:\n",
    "            try:\n",
    "                temp2 = temp.sort_values(by='Predicted MVP Share '+modelo, ascending=False)[:n_rank].reset_index(drop=True)\n",
    "                rank['MVP Rank '+modelo] = temp2['Player']\n",
    "                rank['MVP Share '+modelo] = round(temp2['Predicted MVP Share '+modelo],3)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        rank['Season'] = season    \n",
    "        rank_final = pd.concat([rank_final, rank], ignore_index=True)\n",
    "    \n",
    "    return rank_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_final = create_rank(final_results, 1)\n",
    "rank_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6849308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporadas_antigas(data, seasons, modelos, n_seasons_to_test):\n",
    "    final_results = pd.DataFrame()\n",
    "    metricas = pd.DataFrame()\n",
    "    best_params = []\n",
    "    i = 1\n",
    "\n",
    "    for season in seasons:\n",
    "            \n",
    "        # Separating training and testing bases\n",
    "        season_teste = season\n",
    "\n",
    "        data_train = data[data['Season']!=season_teste]\n",
    "        data_test = data[data['Season']==season_teste]\n",
    "\n",
    "        X_train = data_train.drop(['MVP Votes Share','MVP Rank','Player','Season'], axis=1)\n",
    "        y_train = data_train['MVP Votes Share']\n",
    "\n",
    "        X_test = data_test.drop(['MVP Votes Share','MVP Rank','Player','Season'], axis=1)\n",
    "        y_test = data_test['MVP Votes Share']\n",
    "\n",
    "        initial_results = data_test[['Player','Season','MVP Votes Share','MVP Rank']]\n",
    "        results = initial_results.copy()\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        scaled_X_train = scaler.fit_transform(X_train)\n",
    "        scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "        for modelo in modelos:\n",
    "            \n",
    "            # if modelo=='Elastic Net':\n",
    "            #     continue\n",
    "            \n",
    "            # Opening the models already created          \n",
    "            model = pickle.load(open(path_data + modelo + '.dat', 'rb'))\n",
    "\n",
    "            model.fit(scaled_X_train, y_train)\n",
    "            y_pred = model.predict(scaled_X_test)\n",
    "            metricas = func_metricas(y_test, y_pred, metricas, modelo, season)\n",
    "\n",
    "            apoio = initial_results.copy()\n",
    "            apoio['Predicted MVP Share '+modelo] = pd.Series(y_pred).values\n",
    "\n",
    "            results_sorted = apoio.sort_values(by='Predicted MVP Share '+modelo,\n",
    "                                                ascending=False).reset_index(drop=True)\n",
    "            results_sorted['MVP Rank '+modelo] = results_sorted.index+1\n",
    "\n",
    "            results = results.merge(results_sorted, on=['Player','Season','MVP Votes Share','MVP Rank'])\n",
    "\n",
    "        final_results = pd.concat([final_results,results], ignore_index=True)\n",
    "\n",
    "        if i == n_seasons_to_test:\n",
    "            break\n",
    "\n",
    "        i = i + 1\n",
    "        \n",
    "    return final_results, metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results, metricas = temporadas_antigas(data, seasons, modelos, 21)\n",
    "final_metricas = media_metricas(metricas)\n",
    "final_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_final = create_rank(final_results, 1)\n",
    "# filtered_rank = rank_final[rank_final['Season'] == \"2007-08\"]\n",
    "# filtered_rank = filtered_rank[[\"MVP Rank Real\", \"Season\"]]\n",
    "# filtered_rank\n",
    "rank_final\n",
    "# rank_final.to_csv(\"mvppred2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML Model Environment",
   "language": "python",
   "name": "ml-model"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
